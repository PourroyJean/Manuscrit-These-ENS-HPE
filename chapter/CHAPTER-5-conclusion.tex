\chapter{Conclusion générale}
\label{chap:conclusion}
\glsresetall

        %Ce dernier chapitre conclut le manuscrit de cette thèse consacré au do
      
         
        Le domaine du \gls{HPC} est en pleine croissance et les utilisateurs de supercalculateurs ont un besoin insatiable de puissance de calcul (conduite autonome, recherche sur le climat, villes intelligentes). Des plateformes plus puissantes doivent être développées pour être capables d'analyser le tsunami de données générées par les objets connectés. Ces analyses nécessitent l'utilisation d'algorithmes complexes ne pouvant être exécutés en un temps raisonnable que par des supercalculateurs 10 fois plus puissants que ceux actuellement utilisés. 

\section{Contexte de la thèse}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
        
    
    %\paragraph{Impact du calcul scientifique pour la société}
    
        Depuis plus de 50 ans, les systèmes d’informations participent activement à l’amélioration des connaissances scientifiques et à l’évolution de nos sociétés. Ils sont également des vecteurs indispensables pour augmenter la compétitivité et l’innovation des entreprises grâce à l'utilisation de plateformes de calculs puissantes nommées supercalculateurs. Ceux-ci sont utilisés pour exécuter des applications complexes provenant de différents domaines. Que ce soit dans le domaine de la physique, de la santé ou pour développer de nouvelles intelligences artificielles, les supercalculateurs jouent un rôle décisif dans l'évolution de notre société.
      
    
    %\paragraph{Les performances et challenges NRJ} 
        
        La performance des supercalculateurs a pu évoluer constamment pendant plusieurs dizaines d'années grâce aux améliorations technologiques: augmentation du nombre de transistors (loi de Moore) et de la fréquence des processeurs, complexification de la microarchitecture). Cependant, ces leviers ne sont plus disponibles pour permettre d'élaborer des plateformes plus puissantes. La principale contrainte étant celle de l'énergie, qui, pour des raisons de coût et de faisabilité, ne permet plus de poursuivre la stratégie consistant à augmenter le nombre de serveurs pour augmenter linéairement la performance des supercalculateurs. 

    %\paragraph{Les opportunités}
        Avec la fin de la validité de la loi de Moore, nous devons trouver d'autres moyens d'améliorer la performance de ces plateformes. En effet, l’incapacité des technologies actuelles à réaliser efficacement des calculs et l’explosion du nombre de données à traiter nous obligent à repenser les technologies utilisées et l’architecture des systèmes informatiques. Une solution consiste à utiliser des architectures spécialisées pour le traitement optimisé de certains algorithmes.  Ces architectures vont pouvoir être développées grâce à l'utilisation de nouvelles technologies (\textit{storage class memory} (SCM), mémoire 3D, interconnexion photonique). Ces ruptures technologiques sont telles, qu'elles permettront d'améliorer la performance des architectures de plusieurs facteurs. Les gains de performances ne viendront pas seulement par l'utilisation d'accélérateurs puissants, mais de leur diversité et de la capacité des programmeurs de bien les utiliser. Pour une même application, plusieurs accélérateurs spécialisés seront souvent nécessaires (ASIC, FGPA, DSP, GPU). Grâce au développement d'un protocole de communication universel nommé Gen-Z, ces différentes architectures pourront être interconnectées dans un même système pour travailler ensemble à l'exécution d'une application de façon efficace.
        
    
    %\paragraph{These}
        La capacité à produire plus de résultats avec des ressources limitées devient une nécessité absolue dans un monde hautement compétitif. Cependant, pour réussir, ces accélérateurs, basés sur une technologie de rupture, devront être entièrement caractérisés pour prédire de manière fiable le gain de performance de l'application. 
        
        Afin d'extraire une large part des performances disponibles de ces architectures (très différentes de celles utilisées actuellement), il est impératif de réaliser un travail d'analyse et d'optimisation de performance. 
        Malheureusement, l'évolution des microarchitectures tous les deux ans (modèle Tic-Toc d'Intel) ne nécessitait pas une telle approche. Par conséquent, nous constatons que les outils nécessaires à ce travail sont rares. Sans ce travail de caractérisation et d'analyse de performance, ces architectures sont potentiellement condamnées, car peu d'applications pourront y être exécutées efficacement.
      

\section{Problématique}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
         
         
    \subsection{Problématique de la thèse}
    
        Afin de proposer les meilleures architectures (performance, efficacité énergétique, prix, etc.) pour le développement de nouveaux supercalculateurs, une entreprise comme HPE doit être capable d'identifier et caractériser ces nouvelles plateformes. À cet effet, nous proposons dans ce travail de thèse une suite de logiciels de caractérisation et d'analyse des performances qui, avec la méthodologie appropriée, permettent sélectionner la meilleure plateforme et d'extraire une part significative de ses performances. En rendant les sources des logiciels disponibles, nous voulons sensibiliser les utilisateurs à cette démarche ce qui permettra de poursuivre le travail de caractérisation du nombre croissant de nouvelles plateformes.
 
        Cependant, la caractérisation d'architecture et l'analyse de performance d'applications sont deux domaines très complexes, nécessitant de nombreuses connaissances. Pour permettre le développement des outils manquants, nous avons décrit ces deux difficultés. Afin de faciliter le travail de futurs programmeurs, nous les présentons ces deux études dans les annexes de ce document:
        \begin{itemize}
            \item L'\aref{annexe:CHAPITRE_ARCHITECTURE} couvre l'origine et l'évolution de la microarchitecture des processeurs. Nous présentons les fonctionnalités clés des processeurs modernes qu'il est nécessaire de connaître pour comprendre la performance des applications: pipeline, instructions vectorielles, etc. Nous étudions plus précisément la hiérarchie mémoire qui est la ressource critique de nombreuses applications. 
            
            \item L'\aref{annexe:hardware_counter} présente les compteurs matériels. Ces registres spéciaux du processeur permettent de suivre l'exécution d'une application en mesurant le nombre d'évènements logiciels et matériels. La programmation des compteurs est très difficile et nécessite le recours à des codes bas niveaux. Plusieurs méthodes peuvent alors être employées et demandent une bonne expérience pour être mises en oeuvre.
        \end{itemize}


\section{Contributions principales de la thèse}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
    %- énoncez très clairement ce que vous répondez, finalement, à la question de recherche.
    %    * vous devez exprimer un point de vue original, c’est-à-dire peut-être différent de ce qui s’était fait ou dit avant
    %    * rappelez les positions des principaux auteurs qui traitent de votre thème

    \subsection{État de l'art du domaine du calcul haute performance}
        
        Afin, d'introduire les contributions apportées dans ce travail de thèse, nous avons débuté dans le \autoref{chap:hpc} par la réalisation d'un large état de l'art du domaine du Calcul Haute Performance. Nous avons ainsi commencé par rappeler les fondements du calcul scientifique et de la programmation parallèle. Afin de mieux estimer les performances actuelles des supercalculateurs, nous avons étudié l'évolution de celles-ci au cours des 20 dernières années. Cette étude s'appuie sur le classement du Top500 qui présente, deux fois par an, les 500 supercalculateurs les plus puissants de la planète. Ainsi, nous avons remarqué un ralentissement dans l'évolution de leurs performances depuis 2012 et nous en avons expliqué les principales raisons. 
        
        Après avoir discuté de la nécessité d'accéder à des plateformes de calcul plus puissantes, nous avons étudié les principaux défis empêchant leur développement: le coût, la consommation énergétique, la complexité des microarchitectures, l'explosion du nombre d'architectures disponibles, le besoin de prendre des décisions rapidement et le manque d'expertise. 
        La principale contrainte, liée à l'énergie, nous a ensuite conduits à présenter les opportunités technologiques qui nous permettront de relever ces défis: la présence de nombreux investissements, les nouvelles technologies mémoire (Storage Class Memory (SCM)), les nouvelles technologies d'interconnexion (photoniques) et le protocole universel Gen-Z.
        L'ensemble de ces nouvelles technologies sont utilisées pour développer des architectures innovantes. Ces architectures, très différentes de celles que nous utilisons actuellement, doivent être caractérisées afin de connaître leurs forces et leurs faiblesses: capacité de calcul, débit, latence et capacité de la hiérarchie mémoire, etc. Il est ensuite nécessaire de connaître les besoins des applications afin de sélectionner les architectures les plus adaptées pour son exécution. 
        
        Les outils existants permettant la caractérisation d'architectures et l’analyse de performance d'applications ont été présentés à la fin du \autoref{chap:hpc}. Nous avons pour cela fixé certains critères permettant de les sélectionner. Leur code source doit être libre d'accès pour pouvoir être adaptées à de nouvelles architectures. Leur utilisation doit être la plus simple possible, et répondre à des questions précises. Enfin, ces outils doivent être adaptés aux environnements de calcul hautes performances: possibilité de suivre une partie de l'exécution, réduction de la nécessité de posséder des droits spéciaux (\textit{root}) et facilité d'installation et d'utilisation. Cette étude nous a permis de mettre en évidence la nécessite de développer de nouveaux outils:
        \begin{itemize}
            \item Un outil permettant de caractériser finement les unités arithmétiques et logiques responsables de l'exécution d'\gls{FLOP}, 
            \item Un outil permettant de caractériser l'ensemble des niveaux de la hiérarchie mémoire, matériel critique pour la performance des applications utilisant des motifs d'accès mémoire par \glspl{stride},
            \item Un outil permettant de suivre l'activité du bus mémoire qui est la ressource critique des architectures actuelles,
            \item Un outil permettant d'extraire et de caractériser les zones de codes responsables de la majorité du temps d'exécution des applications HPC.
        \end{itemize}
        
        
    \subsection{Développement de quatre logiciels et d'une méthodologie}
        
        Le point central de ce travail de thèse est le développement de quatre outils permettant la caractérisation d'architectures et l'analyse de la performance d'applications. Contrairement aux outils existants, notre approche réside dans l'utilisation d'outils simples répondant à une question précise. Pour aider à leur utilisation, une méthodologie a ensuite été présentée. Les quatre principaux logiciels développés sont présentés dans le \autoref{chap:dev}:
        \begin{enumerate}
            \item La \autoref{sec:dmlmem} présente le \gls{benchmark} mémoire \verb|DML_MEM|. Ce code permet de caractériser les différents niveaux de la hiérarchie mémoire et de mesurer sa performance lors de l'exécution d'applications utilisant des accès mémoires par sauts (\gls{stride}). La performance de ces applications dépend alors essentiellement de la capacité de ces systèmes à comprendre les motifs d'accès et à anticiper les accès mémoire (\gls{prelecteur}).
            Le benchmark permet de tester différentes tailles de saut et de jeux de données. Ainsi, nous avons pu caractériser plusieurs aspects du matériel: taille d'une ligne de cache, performance de différentes tailles de sauts, performance du préchargement mémoire, optimisation de déroulement de boucle, performance de l'utilisation de pages larges ou encore l'impact de la fréquence et du nombre de coeurs utilisés sur le débit mémoire atteignable.
            
            \item La \autoref{sec:kg} présente le générateur de benchmarks \verb|Kernel Generator|. Ce code permet de caractériser les unités de calcul arithmétique et plus précisément la partie responsable de l'exécution des instructions de calculs sur des nombres à virgule flottante (\gls{FPU}). Le benchmark génère un code assembleur correspondant aux opérations voulues par l'utilisateur (addition, multiplication, FMA (fused multiply-add)).  Différentes tailles d'instructions sont supportées (SSE, AVX2, AVX512) ainsi que les précisions simple et double. Ce code nous a alors permis de vérifier les performances théoriques des unités de calculs (fréquence soutenable, performance atteignable), mais aussi de caractériser le système d'exécution dans le désordre de processeurs modernes. Enfin, nous avons pu expliquer les performances atteintes par le benchmark HPL sur un modèle de processeur Intel, alors deux fois supérieures à celles attendues. 
            
            \item La \autoref{sec:yamb} présente l'outil de suivi d'activité mémoire \verb|YAMB|. Cet outil établit le profil de chaque contrôleur de mémoire en mesurant séparément le nombre de transactions (lecture et écriture) et le nombre de \gls{miss} dans le dernier niveau de cache (LLC). Pour corréler l'activité du bus avec les parties du code qui en sont responsables, le graphique peut être très facilement annoté, depuis le code source de l'application, avec une API C/C++/Fortran.
            
            \item La \autoref{sec:oprofile} présente  l'outil d'analyse \verb|Oprofile++|.
            permettant d'extraire et de caractériser les zones de codes responsables de la majorité du temps d'exécution de l'application. L'outil permet de désassembler le code, d'isoler les \gls{hotspot} et de mesurer leur IPC (Instruction Par Cycle). Il est alors possible de quantifier toutes les possibilités d'amélioration significatives. Cette étape est essentielle pour les décideurs qui peuvent prévoir avec précision le bénéfice potentiel d'une architecture par rapport à l'investissement nécessaire à la transformation du code.
        
        \end{enumerate}
        
        Enfin, nous avons présenté dans le \autoref{chap:methodo} une méthodologie permettant à un développeur de trouver l'architecture la plus efficace pour son application. Cette méthodologie en 5 étapes décrit comment les outils développés dans le \autoref{chap:dev} doivent être utilisés. L'étape $1$ et $2$ permettent de trouver et de caractériser de nouvelles architectures à l'aide de \glspl{benchmark}. L'étape $3$ s'intéresse à la modélisation des performances d'une application. Grâce à ces trois étapes, il est alors possible de sélectionner une architecture candidate dans l'étape $4$. Cette sélection est réalisée en prenant en compte différents facteurs: coût, énergie, performance, etc. Dans l'étape $5$, nous avons expliqué le travail permettant de valider les performances obtenues, et avons discuté des démarches à suivre lorsque les performances atteintes s'éloignaient des performances théoriques.
               
 
 
    \subsection{Les résultats obtenus}
        %Quels sont les principaux résultats de la thèse, ce qu’on peut considérer comme acquis ? 
        %Est-on en mesure, en totalité ou partiellement, de dire qu’on a traité la problématique de départ et apporté une ou des réponses fermes 
   
        Les outils et la méthodologie développés durant ces travaux de thèse ont permis d'obtenir plusieurs résultats.
        
        Les outils de caractérisation sont régulièrement utilisés par l'équipe avant-vente d'HPE, responsable de réaliser les \glspl{benchmark} des applications clients. Récemment, ces outils ont permis de comprendre et d’isoler un bug majeur dans une nouvelle architecture prometteuse (alors inconnue par le fabricant) ne délivrant pas la performance attendue. Cette architecture devait alors être utilisée pour répondre à un grand appel d'offres et a pu être abandonnée avant de réaliser les transformations de codes sur l'application du client.
        
        Le benchmark \verb|Kernel Generator| qui permet de caractériser les unités de calcul en virgule flottante (\gls{FPU}) a été ajouté au logiciel \verb|HPE Confidence|. \verb|HPE Confidence| permet à HPE de valider le bon fonctionnement d'un supercalculateur lors de sa livraison. Grâce à cet ajout, \verb|HPE Confidence| vérifie les bonnes performances de calcul de chaque processeur et permet d’isoler des composants défectueux. 

        Les outils d'analyse de performance ont été utilisés pour remporter le \verb|Hackaton du HPC| \cite{Hackaton}, un concours d’optimisation d’applications. Ce concours, organisé par GENCI (\textit{Grand Équipement National de Calcul Intensif}) et sponsorisé par Intel, avait pour objectif d’optimiser une application de calcul distribué MPI pour la dynamique de systèmes particulaires. En utilisant les outils d'analyse de performance et en appliquant les optimisations adaptées, une accélération d’un facteur 10 a pu être réalisée permettant d'obtenir le prix de la meilleure optimisation\footnote{Résultats du Hackaton du HPC - \url{https://hackathon-hpc.sciencesconf.org/resource/page/id/6}}.
        
        Grâce à la méthodologie développée durant ces travaux de thèse, plusieurs appels d'offres ont pu être remportés. L’un d’entre eux fut lors de l’appel d’offres d’un client stratégique qui autorisait le choix de plateformes spécialisées et la transformation du code. Grâce à notre méthodologie, la performance maximale théorique de l’algorithme pour la plateforme sélectionnée a été atteinte, permettant ainsi d'accélérer l'application d'un facteur 12. 
        
        Durant ces travaux de thèse, nous avons réalisé plusieurs formations pour des clients afin de les sensibiliser à cette approche et à la nécessité de posséder les outils adéquats pour réaliser le travail d’optimisation ou de portage de code.

 
    \subsection{Difficultés}
        
        %- L’intérêt de cette partie est de désamorcer certaines critiques méthodologiques qui pourraient être formulées par les %rapporteurs ou lors de la soutenance : il faut se montrer conscient de certaines limites dues à des carences de méthode %ou aux données elles-mêmes, mais en montrant que ces limites n’invalident pas les résultats proposés.
        
        %- On souligne les obstacles rencontrés et la façon dont on les a surmontés dans la mesure du possible
        
        Au moment de la publication de ce manuscrit, la grande majorité des outils a permis d'obtenir des résultats sur les architectures \verb|x86|. Nous nous sommes appuyés sur ces architectures pour développer nos outils. En effet, l'expérience et les connaissances de ces architectures nous ont permis de développer et vérifier les résultats produits. Comme expérimenté dans le \autoref{chap:methodo}, nous avons utilisé ces architectures comme démonstrateur afin d'illustrer l'utilisation des outils et de notre méthodologie. Concernant l'étude d'architectures innovantes, un accélérateur a pu être caractérisé. Néanmoins, les résultats correspondants ne peuvent pas être publiés pour des raisons de confidentialité. Des architectures ayant un potentiel pour l'exécution d'application sont développées et ce travail de caractérisation doit être poursuivi. 
        
        Nous avons développé ces outils en favorisant au maximum leur portabilité. Pour cela, nous avons dû réduire au minimum le nombre de compteurs matériels utilisés. En effet, la compatibilité des compteurs d'évènements est très faible entre différentes architectures. Pour assurer la plus grande portabilité des outils de suivi de performance, nous avons choisi de nous appuyer sur la couche de programmation de compteurs maintenue par le noyau Linux (\verb|Perf Events|). Actuellement, le benchmark du \verb|Kernel Generator| ne permet de caractériser que les architectures utilisant des jeux d'instructions x86. Cependant, son développement a été réalisé pour faciliter l'ajout de nouvelles instructions, mais aussi d'un langage assembleur différent.


\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    
    
    Ce travail de thèse présente le domaine du Calcul Haute Performance et discute du besoin de posséder les outils adéquats pour permettre l'utilisation de nouvelles architectures de calculs dans les prochaines génération de supercalculateur \gls{exascale}. Ce travail est fondamental pour pouvoir sélectionner les bonnes architectures et exécuter les applications de façon la plus optimisée possible. Cependant, l'évolution permanente des performances des processeurs a placé le domaine de la caractérisation d'architecture et de l'analyse de performance a longtemps en second plan.
    Face à la complexité du domaine du HPC et celle du travail à réaliser, ce manuscrit s'est voulu pédagogique pour partager le maximum de connaissances acquises durant la thèse. Pour cela, nous avons commencé dans le \autoref{chap:intro} par rappeler les principes fondamentaux des supercalculateurs (simulation numérique, programmation parallèle). Nous nous sommes ensuite intéressés aux défis à relever pour développer les prochaines générations de supercalculateur. Afin de tirer parti des nouvelles architectures, nous avons motivé le besoin de posséder les outils permettant de les caractériser, mais aussi ceux permettant de suivre leur activité. Dans le \autoref{chap:dev} nous avons présenté nos principales contributions qui sont le développement de deux outils de caractérisation d'architectures et deux outils d'analyse de performance. Les logiciels développés sont simples et permettent de répondre à quelques questions précises. Leur efficacité réside dans la logique de leur utilisation. Afin d'utiliser au mieux ces outils, nous avons décrit une méthodologie dans le \autoref{chap:methodo}.
        
     
\section*{Perspectives}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %    * Une thèse peut être considérée comme le début d’un processus de recherche
    %    * il y a toujours des choses à compléter, et vous ou un autre chercheur compléterez les travaux.
    
    Ce travail constitue le début d'un projet de plus grande envergure visant à caractériser et analyser la performance des applications sur de nombreuses architectures. La prochaine étape est de poursuivre le développement de ces outils pour supporter de nouvelles architectures, mais aussi pour ajouter certaines fonctionnalités aux outils existants:
    \begin{itemize}
        \item \textbf{DML\_MEM}: ajouter une fonctionnalité permettant de détecter automatiquement un problème de la microarchitecture en exécutant de multiples combinaisons \{\verb|taille de saut|, \verb|taille de jeu de données|\},
        \item \textbf{Kernel Generator}: permettre l'utilisation de nouvelles instructions vectorielles (rotation, décalage...) pouvant être de tailles différentes dans le même microbenchmark,
        \item \textbf{Oprofile++}: adapter une partie du code pour réutiliser certaines fonctionnalités proposées par l'outil \verb|perf| permettant de faire la correspondance entre les instructions assembleur et leur adresse mémoire.
        \item \textbf{Méthodologie}: utiliser des modèles de performances plus complexes existant dans la littérature.
    \end{itemize}

    Notre prochain objectif est d’appliquer notre méthodologie pour la caractérisation de plateformes telles que les processeurs AMD, ARM ou les accélérateurs NEC. Ce travail sera réalisé pour répondre à un appel d’offres pour la société ARAMCO (recherche pétrolière). Pour cela, un générateur de \glspl{benchmark} générant des microbenchmarks de code de stencil sera créé permettant de caractériser les architectures pour ces codes. Un second travail consiste à pouvoir exécuter les benchmarks à intervalles réguliers sur un supercalculateur permettant de générer des traces \textbf{de quoi}. Grâce à des méthodes statistiques et d'apprentissage machine, ces données nous aideront à découvrir et anticiper les pannes matérielles. Enfin, comme la réussite de ce projet repose sur l’aide de la communauté, nous avons prévu de poursuivre la formation et sensibilisation à cette démarche auprès de nombreux clients industriels ainsi que des spécialistes avant-vente HPC.
    

%  \cite{Straatsma2017} indique qu’une grande difficulté pour les outils d’analyses utilisés sur les architectures exascales sera de retirer une informations utiles de toutes ces mesures. Lire les compteurs sur des milliers de coeurs, synchroniser ces mesures est déjà une difficulté. Mais il faudra aussi tirer un valeur de ces valeurs qui ne pourra pas être fait par des humains. Il faut donc se tourner vers des algorithmes statistiques ou des techniques de machines learning (source ?).

